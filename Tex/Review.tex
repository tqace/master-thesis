\chapter{研究现状}



\section{基于视觉特征的服装检索研究现状}

服装检索的发展经历了两个阶段,分别是基于文本和基于内容的服装检索。基于文
本的服装检索通过关键字或者更加自由形式的文本信息来描述商品,然后通过文本匹
配算法进行服装商品的检索,其本质是以文本搜图。目前,像服装购物平台淘宝等主流
电子商务网站检索服装图像都是以 TBIR(Text-based Image Retrieval)技术为主,TBIR
一般通过关键字检索,其特点是快速精准,但是随着服装种类与数量的不断迅速增长,
TBIR 的不足之处也开始显现出来:现在人们对于服装细节的要求越来越高,然而采用
关键字去标注服装图像无法全面准确的表示服装的细节信息;TBIR 需要人工的对海量
的服装图像做标注,工作量很大;人工标注有时会缺乏客观性,这会直接导致检索结果
的偏差。因此,对基于内容的服装图像检索算法的研究很有必要性,CBIR 通过学习图
像的视觉语义特征进行检索,可以弥补 TBIR 的很多不足。

CBIR 算法首先会抽取图像的特征,然后将该特征和检索库里的特征对比,计算相
似度,按照相似性的大小来排序从而可以得到最终的检索结果。初期的 CBIR 算法一般
致力于更好的提取服装的视觉特征,服装是整个服装图像中的主体,因其款式多样、颜
色鲜明、细节突出等特点,相对与自然景象或者生活中其他常见物体等背景信息更加具
有区分度。从服装的这些特点中我们可以抽取服装的纹理、颜色、形状这三大视觉特征,
对这三种特征的提取是初期 CBIR 算法的主要方向:
\begin{itemize}
\item[1.]纹理特征:服装面料最为明显,最具区分性的特征就是纹理,纹理一般情况下以
图像的某种局部特性表现出来,纹理的多样性决定了服装的外在美观程度,更好的提取
服装图片的纹理特征十分有利于检索得到相似度高的服装图像。传统提取纹理特征的方
法主要有四种:频谱法、统计法、结构法和模型法。
纹理特征的提取算法最好具有旋转不变性,Ojala等人提出的LBP纹理分析方法具有旋转不变性的优点,但该方法只使用了服装图像的局部信息去提取特征,没有很好
的利用图像的全局信息\cite{ojala2002multiresolution}
。Manthalkar等人的方法具有旋转不变性和尺度不变性,然而
该方法牺牲了纹理的方向信息\cite{manthalkar2003rotation}。

\item[2.] 颜色特征:颜色是服装的重要构成部分,是图像的一种显著的视觉特征,其对于
图像检索也一直是十分重要的特征。早期对颜色特征的提取主要通过统计图像像素点的
值,近阶段则是偏向于研究图像颜色信息空间分布的检索方法,Pass 等人统计图像中各
颜色最大连续区域的像素值,将其作为颜色特征\cite{pass1996comparing};Strieker 等人将图像划分,再分别
对划分后的各个子区域进行颜色特征的统计提取\cite{stricker1997spectral}。总体的来说,目前基于颜色信息
的检索方法主要考虑对全局以及局部颜色特征的抽取。

\item[3.] 形状特征:形状是决定服装款式多样性的重要因素,蕴含了服装的设计理念和
风格,其对于人的视觉感受也是十分重要的因素。形状特征的提取被广泛应用于 CBIR,
除了如何更好的提取形状特征之外,不同形状特征之间的相似度计算也是近来被探索的
课题。
对形状特征的提取注重关注服装图像的轮廓信息,以及更好的处理区域特征。轮廓
特征指服装的边界形状信息所包含的特征,相关参数有边界点、面积、周长等,相关研
究有 Livarinen 等人提出链码直方图\cite{iivarinen1997comparison};Berretti
等人提出基于平滑曲线分解特征等\cite{berretti2000retrieval}。区域特征指的是图像服装区域内部所包含的信
息,常用矩的方法, Chin等人提出几何不变矩，可以更好地提取形状特征\cite{teh1988image}。对形状特相似性度量的
研究:Peter 等提出 K 最近邻图\cite{kontschieder2009beyond};Bai 等人利用了形状特征之间的相似性与图之间
的相互关系,将形状特征间的相似性构建为图,更有效得去度量形状间相似性\cite{bai2010learning}。
\end{itemize}

\section{基于语义特征的服装检索研究现状}
传统的 CBIR 方法采用颜色、形状、纹理等视觉特征,这些特征较为底层,使用的
分类器大多是浅层分类器,如支持向量机。这种基于底层视觉特征的检索系统和人类视
觉体系对图像的理解存在着语义鸿沟,即对于不同的图片,机器从低级的可视化特征得
到的相似性和人从高级的语义特征得到的相似性之间的不同\cite{卢兴敬2008基于内容的服装图像检索技术研究及实现}。所以,即便图像检索
领域在对底层视觉特征的提取有了很大进展,提出了一系列不同的方法,但由于语义鸿
沟的存在,图像检索依然面临着巨大的挑战,我们希望机器可以像人一样理解识别图片
内容,则需要从更高层次去分析图片,现阶段最有希望解决这个语义鸿沟的技术是机器
学习。机器学习是一门涉及统计学、概率论、优化算法等领域的交叉学科,旨在研究如
何让计算机像人一样去学习新的知识,模仿人的行为,不断的通过学习提高自己。机器
学习算法的学习流程是:人为的将大量数据输入到计算机程序,让计算机去处理这些海
量数据,使其发现并总结出这些数据背后所蕴含的规律等隐含信息,机器学习的优势是
可以凭借计算机的高性能计算从大数据中学习得到人类无法轻易总结出的规律。21 世
纪以来,机器学习技术不断发展成熟,应用范围也从开始单纯的字符识别慢慢多样化,
比如生物信息中的基因大数据分析,金融行业中通过对历史数据规律的分析预测市场走
向。

在机器学习中,深度学习技术近年来得到了爆发性的发展,深度学习在计算机视觉、
自然语言处理、多媒体、语音识别等方向均取得了巨大的成功,极大的推动了人工智能
领域的发展进程。深度学习作为机器学习领域的一个分支,起源于 80 年代的 BP \cite{rumelhart1988learning}神经网
络,这是一种对误差逆向传播的多层前馈神经网络,其核心思想是通过梯度下降法不断
优化网络,使得算法不断往误差的最小化方向参数调优。深度学习发展如此迅猛主要得
益于两个方面的原因:计算机的计算能力快速发展,神经网络的训练可以部署在 GPU
上并且可以并行训练,这使得大规模的神经网络可以训练;另一个原因则是大数据的快
速发展,训练数据是机器学习算法的核心之一,随着互联网的发展,日常产生的数据呈
指数级增长,这些海量的标注数据促进了深度学习模型的训练。相对于传统机器学习,
深度学习可以自动的找出分析问题所需要的重要特征,随着神经网络的加深,可以抽取
上层次的语义信息。深度网络中比较有代表性的是卷积神经网络,Lecun 等 提出的
LeNet-5\cite{lecun1998gradient} 在手写字符识别领域的成功应用引起了学术界对于卷积神经网络的关注,2012
年 Alex Krizhevsky 提出 AlexNet\cite{krizhevsky2012imagenet},一举摘下了视觉领域竞赛 ILSVRC 2012 的桂冠,在
百万量级的 ImageNet\cite{deng2009imagenet} 数据集合上,效果大幅度超过传统的方法 [7],这成为卷积神经网
络的一个历史性时刻,AlexNet 之后,不断有新的卷积神经网络模型被提出,从 VGG\cite{simonyan2014very}、
GoogLeNet\cite{szegedy2015going}、Res-Net\cite{he2016deep} 到近期的 Res-NeXt\cite{xie2017aggregated}、SE-Net\cite{hu2018squeeze}。

和基于视觉特征类似,对于区域信息特征的学习是基于语义特征的服装检索一个重
要研究方向,CVPR2016 的工作 Fashion-Net\cite{liu2016deepfashion} 在服装检索中通过关键点信息来对局部特
征进行对齐操作,通过第一步预测出关节点,然后通过关键点信息和池化操作获得对应
的局部特征,这种做法可以较为准确的定位到服装所在区域,但是需要对于关键点的标
注数据进行训练,资源消耗较大。在服装检索的问题上,同款服装的不同图片的相似度
应大于不同款服装的相似度,因此度量学习在网络训练时被广泛使用。常用的度量学习
损失方法有对比损失(Contrastive loss)
、三元组损失(Triplet loss)
、困难样本采样三元
组损失(Triplet hard loss with batch hard mining, TriHard loss)等。除了以度量损失函数
作为网络训练的监督信息以外,服装的低层信息,比如颜色、纹理、形状等也常被作为
辅助监督,这种多任务学习的方式使得网络具有更强的表达能力,学习得到语义信息更
加丰富的特征。

\section{深度卷积网络研究现状}
目前情况下，包括图像检索在内的许多计算机视觉任务，在大部分情况下都会使用常用的基础分类网络作为其骨干网络充当特征提取器，这些主流的分类网络的性能已经在ImageNet得到证明。最经典的卷积神经网络是Yann LeCun在1998年设计并提出LeNet，这个用于识别手写字符的网络规模较小，但是包含了现在卷积神经网络的最基本组件：卷积层，池化层，全连接层。Alex Krizhevsky于2012年提出的AlexNet是卷积神经网络的一大步：AlexNet使用ReLU取代Sigmoid作为激活函数，成功解决了Sigmoid在网络较深时的梯度弥散问题；训练时采用了Dropout策略，随机忽略一部分神经元，可以有效避免模型的过拟合；引入了最大池化层而不是像之前只使用平均池化层，这有效的提升了特征的丰富性；使用CUDA加速神经网络训练，有效利用了GPU的计算能力。AlexNet被提出之后，深度学习飞速发展，越来越多性能优异的基础网络随之被提出，下面简要分析几个主流的基础网络：
\begin{itemize}
  \item [1.]VGG：相比AlexNet，VGG的一个改进是采用连续的几个3x3的卷积核代替AlexNet中的11x11或者5x5的较大卷积核。对于给定的感受野，采用堆积的小卷积核是优于采用大的卷积核，因为多层非线性层可以增加网络深度来保证学习更复杂的模式，此外小的卷积核也意味着更少的参数量，更低的计算复杂度。总结性的来说，VGG在控制计算量增长的同时将网络架构做的更深更宽，分类效果显著提升。\input{Img/vgg}
\item [2.]Inception：又被称为GoogLeNet，实际上Inception指的是GoogLeNet的核心结构。一般来说提高网络表达能力最直接的方法就是增加网络的深度和宽度，但是直接这么做会带来一些问题：
\begin{itemize}
  \item [(1)]相对更深更宽的网络不可避免的会增加参数量，而过多的参数量容易导致过拟合。
  \item [(2)] 随着网络的深度的增加，反向传播时会出现梯度消失的问题，导致网络很难优化。
  \item [(3)] 计算量增加，会消耗更多的计算资源。
\end{itemize}

Inception结构针对限制神经网络性能的主要问题对传统的卷积策略不断改进，Inception v1设计出了多路并行的卷积模块，不同分支的卷积核大小不同，分别有1x1,3x3,5x5三种尺度，这么做的好处是可以以不同大小的感受野去学习得到不同的特征，卷积操作之后，不同分支的特征通过拼接的方式做融合。
\input{Img/inception-v1}
Inception v2\cite{ioffe2015batch}基于Inception v1做了进一步的改进，提出了有重大意义的BN(Batch Normalization)。训练深度神经网络时，作者抛出一个叫做“Internal Covariate Shift”的问题，这个问题指在训练过程中，第n层的输入就是第n-1层的输出，在训练过程中，每训练一轮参数就会发生变化，对于一个网络相同的输入，但n-1层的输出却不一样，这就导致第n层的输入也不一样，BN的提出就是为了解决这个问题。在传统机器学习中，对图像提取特征之前，都会对图像做白化操作，即对输入数据变换成0均值、单位方差的正态分布，卷积神经网络的输入就是图像，白化操作可以加快收敛，对于深度网络，每个隐层的输出都是下一个隐层的输入，即每个隐层的输入都可以做白化操作，BN就是在训练中的每个mini-batch上做了白化，可以有效防止梯度消失并加速网络训练。

\item [3.]ResNet：由微软研究院的Kaiming He等提出的ResNet，通过使用ResNet Unit成功训练出了152层的神经网络，其效果非常优异，在ILSVRC2015比赛中夺得头筹。

提出残差学习的思想。传统的卷积网络或者全连接网络在信息传递的时候或多或少会存在信息丢失，损耗等问题，同时还有导致梯度消失或者梯度爆炸，导致很深的网络无法训练。ResNet在一定程度上解决了这个问题，通过直接将输入信息绕道传到输出，保护信息的完整性，整个网络只需要学习输入、输出差别的那一部分，简化学习目标和难度。VGGNet和ResNet的对比如下图所示。ResNet最大的区别在于有很多的旁路将输入直接连接到后面的层，这种结构也被称为shortcut或者skip connections。

\input{Img/resnet}
\item [4.]SENet:近年来，为了提升网络性能，多数工作从空间纬度展开，比如Incepion使用
多尺度的卷积核以获取并聚合不同感受野的特征，另外比较具有代表性的有将注意力机制
引入到空间维度上去，这些工作都取得了很好的效果。而SENet则引入了另一种思路：是否可以考虑特征通道之间的关系以提升网络性能？SE是Squeeze-and-Excitation的缩写，
Squeeze和Excitation则是SENet核心模块的两个关键操作，模块具体流程如下：
\begin{itemize}
  \item [(1)] 对一个三维的特征图做Global average pooling，得到特征维度为${c\times1\times1}$，其中c为特征图的通道数，这个操作成为Squeeze。
  \item [(2)] 随后为两个FC层（Fully-connected-layer）去学习通道之间的相关性，其中第一个FC层将输入维度降低至原来的1/16，并经过ReLu，第二个FC层再将特征升至原来的维度。
  用两个FC层的好处是可以增加非线性以更好的建模通道相关性，并且可以大幅度减少参数量。
  \item [(3)] 最后通过Sigmoid将特征归一化至0到1之间，代表每个通道的重要程度，并将权重点乘至原特征图上。
\end{itemize}
\end{itemize}


