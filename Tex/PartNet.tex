\chapter{基于注意力机制的局部对齐网络}

\section{引言}
基于深度学习的服装检索网络一般可以概括为两个子网络：表示和匹配。表示网络即特征提取器，一般使用在ImageNet预训练的主流深度卷积网络，比如VGG、ResNet等主流骨干网络；
匹配网络对所提取特征进一步学习，以获得更适合服装检索这个任务的特征。特征提取器输出的特征经过Pooling之后得到一个向量之后，一般都会引入度量学习去做监督，
使同款的服装特征相似度提高，不同款的服装特征相似度降低,特征的相似度或者距离衡量常用余弦相似度。
常用的度量学习损失有Contrastive loss\cite{hadsell2006dimensionality}、Triplet loss\cite{schroff2015facenet}等，其公式分别如下所示

\textbf{contrastive 公式}

\textbf{triplet 公式}

大家在早期对服装检索的研究主要关注在全局信息上，即对整幅图提取一个全局的特征，但是后来这种方式遇到了瓶颈，大家开始慢慢把研究的方向转向对局部特征的学习与表示。
对于服装图像来说，全局信息包含了更加丰富的语义信息，但是对局部信息的抽取也非常有帮助，因为不同款式的服装有的时候仅仅有着细微的差别，在全局特征中，这些重要
但是不明显或者所占区域比例较小的局部信息会被Average Pooling稀释掉，如果可以通过某种方式将这个区域的特征单独提取出来，或者强化这个局部区域的特征强度，
对检索结果将会带来巨大的收益。比较常用的局部特征提取方法有对输入图像的切分\cite{varior2016siamese}，或者网格\cite{li2014deepreid}等，这种方式直接获取局部特征
比较简单直接，但是也有其相应的不足之处：同款服装的不同拍摄图像摆放位置及形状不一定相同，两幅图的局部特征并不能很好的对齐。
Fashion-Net使用关键点信息协助局部的定位，网络第一阶段先生成对关键点位置的预测，第二阶段根据关键点位置对局部信息Pooling。通过关键点的方式可以很好的解决局部部件对齐
的问题，但是这个方法需要训练样本有对应关键点的标注信息，带来的资源消耗较大。

近年来，注意力机制（Attention Mechanism）在深度学习的各个领域都被广泛的使用，从自然语言处理到语音识别再到计算机视觉，都很容易看到注意力模型的存在。深度学习中的
注意力机制其实借鉴自人类视觉系统的注意力机制。人类的视觉注意力机制的本质是我们大脑的一种信号处理机制，首先对眼睛观测到的图像做全局的扫描和理解，分析之后会把注意力
放在需要重点关注的区域，从而抓取更多的细节信息，一定程度上屏蔽相对无关的信息，人的视觉注意力机制有效的提高了对视觉信息的理解效率和效果。在计算机视觉领域，
注意力模块往往指一个额外的网络模块，这个模块可以给输入的信息分配不同的权重之后再输出，特殊条件下，如果权重大小只能是0或者1时，就包括了切分或者网格的处理方式，
本节中的注意力机制特指软注意力机制（Soft Attention），即注意力权重为0到1之间的任意值。注意力模块可以直接嵌入到神经网络之中的，Soft Attention的权重输出是可微的，
所以整个模型可以进行端到端的训练。

\section{方法与实现}
\subsection{度量学习}
服装检索任务的目标是在由很多款式服装图像组成的检索库中找到和检索图片（query）相同款式的服装。这个任务可以被看作一种排序问题：给定一个query，那么检索库中和query
相同款式的服装相对于与其不同款式的服装应当和query更加相似。

基于此，本方法引入度量学习训练模型，训练样本组成方式如下：对于一个批次（Batch）的样本${\mathcal{B} = \{I_{1},I_{2},\cdots,I_{N}\}}$，我们从中组成一系列三元组，
${\mathcal{T} = \{(I_{a},I_{p},I_{n})\}}$，其中($I_{a},I_{p}$)是一对正样本对，表示这是来自同一款服装的两幅照片；($I_{a},I_{n}$)是一对负样本对，表示来自不同款式服装的
两幅照片。

由于检索任务的本质是一个排序问题，我们使用三元组损失（Triplet loss）函数优化网络，其数学表达式为：
\begin{equation}
\label{eq:partnet:1}
\mathcal{L}(I_{a},I_{p},I_{n}) = \max \{d(h(I_{a}),h(I_{p})) - d(h(I_{a}),h(I_{n})) + m,0\}
\end{equation}
这里$(I_{a},I_{p},I_{n}) \in \mathcal{T}$，$m$(margin)是我们认为负样本对之间的距离和正样本对之间应该有的距离差值，借鉴已有的工作\cite{schroff2015facenet}，
在我们的实现中，$m$取了0.2。$d(\mathbf{x},\mathbf{y})=\left\|{\mathbf{x} - \mathbf{y}}\right\|_{2}$，代表了欧几里得距离，即欧式距离。$h(I)$代表将图像$I$输入网络并提取得到其特征。
所以我们可以得到如下完整的损失函数定义：
\begin{equation}
\label{eq:partnet:2}
\mathcal{L}(\mathcal{T}) = \frac{1}{\left|\mathcal{T}\right|} \sum_{(I_{a},I_{p},I_{n}) \in \mathcal{T}} \mathcal{L}(I_{a},I_{p},I_{n})
\end{equation}
公式里的$\left|\mathcal{T}\right|$代表这个Batch里所包含所有三元组的个数。

\subsection{局部对齐网络}
网络的第一阶段是一个特征提取器，这个特征提取器是一个深度全卷积神经网络（FCN），其输出是一个特征图，随后将其作为局部特征提取网络的输入，由其提取并输出局部特征。
与直接对输入图像做空间上的水平、竖直切分或者使用网格切分的方式不同，我们的目的是提取对齐之后的局部特征。

局部对齐网络如图\ref{fig:partnet}所示，包含了几个分支，每个分支都以FCN的输出作为输入，并检测到一个具有判别力的独立的局部区域，最后将这个区域的特征提取并输出。
我们将FCN所提取的特征图用一个三维的张量\textbf{T}表示，其每个维度大小为$w\times h \times c$，代表宽度为$w$，长度为$h$，通道数为$c$的张量。局部对齐网络的每个分支
都会生成一个二维的掩膜$M_{i}$，$i$代表第$i$个分支，其大小为$w\times h$，$M(x,y)$的大小表示$(x,y)$这个区域的特征对应的权重。
那么对于第$i$个分支来说，其输出特征$\textbf{T}_{i}$可表示为如下形式：
\begin{equation}
\label{eq:partnet:3}
\textbf{T}_{i}(x,y,c)=\textbf{T}(x,y,c) \times M_{i}(x,y)
\end{equation}
得到$\textbf{T}_{i}$之后，会通过全局平均池化（Global average pooling）操作得到一个向量，$\textbf{f}_{i}=AveragePooling(\textbf{T}_{i})$。
随后用一个线性降维层对这个向量降维，降维层采用全连接层实现，$\bar{\textbf{f}_{i}}=\textbf{W}_{FC_{i}}\textbf{f}_{i}$。接下来，我们将来自所有分支的局部特征拼接起来：
\begin{equation}
\label{eq:partnet:4}
\textbf{f}=[\bar{\textbf{f}_{1}}^\top,\bar{\textbf{f}_{2}}^\top,\cdots,\bar{\textbf{f}_{N}}^\top]^\top
\end{equation}
最后对拼接后的特征做$L_{2}$归一化，得到公式\ref{eq:partnet:1}中的$h(I)$。
\input{Img/partnet}
\subsection{注意力模块}

