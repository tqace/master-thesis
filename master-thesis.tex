% This is file `seuthesix.tex',
% This file is the source of the documentation of the `seuthesix' class.
% Copyright (c) 2016 James Fan, email: zhimengfan1990@163.com
% License: GNU General Public License, version 3
%This file is part of ``seuthesix'' package.
%``seuthesix'' is free software: you can redistribute it and/or modify
%it under the terms of the GNU General Public License as published by
%the Free Software Foundation, either version 3 of the License, or
%(at your option) any later version.
%``seuthesix'' is distributed in the hope that it will be useful,
%but WITHOUT ANY WARRANTY; without even the implied warranty of
%MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
%GNU General Public License for more details.
%
%You should have received a copy of the GNU General Public License
%along with this program.  If not, see <http://www.gnu.org/licenses/>.

\documentclass[figurelist,tablelist,nomlist,masters]{Style/seuthesix}
\usepackage{hologo}
\usepackage{fancyhdr}
\usepackage{emptypage}
\usepackage{pdfpages}
\usepackage{gensymb}
\usepackage{enumitem}
\setlist[enumerate]{wide=\parindent}% only indent the first line
\setlist[itemize]{wide=\parindent}% only indent the first line
\setlist{nosep}
\setcounter{secnumdepth}{3}

\fancypagestyle{plain}{
  \fancyhead{}
  
  \fancyhead[CE,CO]{\leftmark}

  \fancyfoot[CE,CO]{\thepage}
  }

\begin{document}
\pagenumbering{Roman}
\pagestyle{plain}
\chapter*{摘要}
\markboth{摘要}
  随着社会开始走向智能化，网购成为人们的主要消费方式，消费者搜索商品的过程一般通过电商平台的检索算法实现。对于服装购物而言，
  传统的基于文本描述的服装检索算法（TBIR）越来越不能满足人们精细的检索需求。得益于深度学习和计算机视觉的蓬勃发展，基于图像内容的服装检索算法（CBIR）
  成为主流，即根据消费者上传的服装图像检索其同款服装。近阶段，对图像局部区域信息的抓取和对齐是该领域研究的一个热门方向，因此，
  设计出一个有效提取服装细节信息的深度网络具有很大的实用价值。

  本文在总结已有工作的基础上，针对服装图像局部语义信息的提取和对齐问题，主要工作贡献如下：
  \begin{itemize}
    \item[1.]提出基于注意力机制的局部对齐网络。该网络采用多个局部分支并行的架构，单个分支是一个基于注意力机制的局部特征提取器，注意力模块包含空间注意力和通道注意力
      两个子模块，可以互相促进更好的学习注意力分布，不同的分支可以自适应的学习得到不同的注意力分布图，通过多个不同的局部区域特征联合表示有效提升了模型的表达能力。此外，基于在线三元组损失（Online Triplet Loss）
      ，提出一种跨域的样本挖掘算法，该算法基于源域训练的模型，在目标域挖掘并标注无标签样本，以此来扩充训练数据并用于新一轮的训练，对挖掘得到目标域样本的学习使得模型可以适应目标域的数据分布，提升模型的泛化能力。
    \item[2.]提出基于多粒度切分的局部对齐网络。对原图切分得到局部区域输入网络会面临过拟合的问题，通过对特征图感受野的分析，本方法对特征图实施
      切分操作，可以在凸显局部信息的同时保留一定的上下文信息，模型性能得到大幅提升。提出环形切分的创新性切分方式，并通过与横向、纵向切分方式的组合，
      保证局部关键信息特征的完整性。另外，启发式的提出多粒度的切分策略，通过融合不同的切分尺度的局部特征，有效提升模型的表达能力。
  \end{itemize}
  \vspace{3ex}
  \textbf{关键词:} 服装检索，深度学习，注意力机制，多粒度

\chapter*{ABSTRACT}
\markboth{ABSTRACT}
  With the development of society towards intelligent age, online shopping has become the main way of consumption, 
  the process of consumers searching for goods is generally implemented by the retrieval algorithm of the e-commerce platform. 
  The traditional Text-Based Image Retrieval(TBIR)
  algorithm can no longer meet the increasingly comprehensive needs when people doing online shopping. Benefits from the flourishing of deep learning, 
  Content-Based Image Retrieval(CBIR) has become mainstream. Recently, grasping and aligning the local area information of the input  clothing image is a 
  popular direction in this field. 
  
  On the basis of summarizing the existing work, following contributions are made to the extraction and alignment of local information 
  of clothing images:
  \begin{itemize}
    \item[1.]Part alignment network based on attention mechanism is proposed. This network uses multiple local branch parallel architectures, 
      and one single branch is a local feature extractor based on the attention module. Although each branch has the same structure, it can be adaptively learned to obtain different attention maps.
      In addition, a cross-domain sample mining algorithm is proposed, which is based on the deep model trained in the source domain and can digging and labeling unlabeled samples in the target domain.
    \item[2.]Multi-granularity part alignment network is proposed. This method performs a partition operation on the feature map rather than the input image to extract local information, 
      and the performance of is improved by a large margin. And through the combination of horizontal, vertical and annular partition methods to ensure the integrity of the key part information.
      In addition, The proposed multi-granularity partition strategy effectively enhances the model by merging local features of different partition scales.
  \end{itemize}
  \vspace{3ex}
  \textbf{Keywords:} Clothing retrieval, Deep learning, Attention mechanism, Multi-granularity


\tableofcontents
\listofothers

\mainmatter
\pagenumbering{arabic}
\input{Tex/Intro}
%\input{Tex/Review}
\input{Tex/PartNet}
\cleardoublepage 
\input{Tex/MGN}
\cleardoublepage 
\input{Tex/Conclusion}

\bibliographystyle{Biblio/seuthesix} 
\clearpage
\pagestyle{plain}
\chapter*{致 谢}
\markboth{致谢}
硕士三年，倏忽而过，回顾这三年的硕士生涯，仿佛一切都在昨天，期间的努力、茫然、喜悦和收获都历历在目。在这里，衷心的向诸位老师、同学、亲人、朋友致以发自内心的谢意。

感谢汪鹏老师。汪老师是我的指导老师，从开题报告到论文的撰写，汪老师给了我诸多的建议，汪老师的学术态度让我时刻铭记要怎样做科研，这份认真、严谨的科研态度是我终生的
学习目标。

感谢刘静研究员。刘老师是我的校外指导老师，在自动化所的一年半的实习时光，刘老师是我的良师也是益友，她有着积极的科研态度和强大的科研能力，敦促、帮助我度过了很多学术上的难关。

感谢我的同学王炜和王引。一起在地平线实习的几个月里，多亏了你们在生活上的照顾和陪伴，感谢学习生涯有你们的出现。

感谢图像视频分析小组的诸位成员，方治伟师兄、付君师兄、郭龙腾、陈亮雨、刘飞、何兴建、卢诗晨、蔺俊琦，感谢你们分享的每一篇论文，感谢你们陪我吃的每一顿饭，
感谢一路以来的关爱。

\addcontentsline{toc}{chapter}{致谢}
\bibliography{Biblio/ref}       
\end{document}
